{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import csv \n",
    "import sqlite3 as sql\n",
    "import struct, time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. **Text files**\n",
    "\n",
    "Perform the following operations on plain `txt` files:\n",
    "\n",
    "+ create a list of integrer numbers and then save it to a text file named `data_int.txt`. Run the `cat` command to print the content of the file.\n",
    "+ create a matrix of 5x5 floats and then save it to a text file named `data_float.txt`. Use the `cat` command to print the content of the file.\n",
    "+ load the `txt` file of the previous point and convert it to a `csv` file by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data_int.txt file:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "The data_float.txt file:\n",
      "8.396183909131209600e-01 6.032002381726573326e-01 6.171695879005029139e-01 6.076405193974087071e-01 1.589246423790511287e-01\n",
      "2.769346247443837949e-02 7.340335760595270154e-01 7.218707800357253568e-01 1.478298512130327147e-02 7.656594138764463153e-01\n",
      "5.955200091588666034e-01 9.378368129828917876e-02 5.801747432329045218e-01 5.836971440261097266e-01 7.308796021543711996e-01\n",
      "4.197019102857177941e-01 8.375664861322515975e-01 5.593613710356997171e-01 5.302119779358047680e-01 7.199878896139844109e-02\n",
      "5.220848693964087461e-01 4.310117052757719280e-01 4.860682028232585772e-01 9.950213630104044471e-01 6.700259672794895982e-01\n",
      "The data_float.csv printed: \n",
      "0.839618390913121,0.6032002381726573,0.6171695879005029,0.6076405193974087,0.15892464237905113\n",
      "0.02769346247443838,0.734033576059527,0.7218707800357254,0.014782985121303271,0.7656594138764463\n",
      "0.5955200091588666,0.09378368129828918,0.5801747432329045,0.5836971440261097,0.7308796021543712\n",
      "0.4197019102857178,0.8375664861322516,0.5593613710356997,0.5302119779358048,0.07199878896139844\n",
      "0.5220848693964087,0.43101170527577193,0.4860682028232586,0.9950213630104044,0.6700259672794896\n"
     ]
    }
   ],
   "source": [
    "#Creating a list og integrer numbers \n",
    "list_of_integer = [1, 2, 3, 4, 5]\n",
    "with open('data_int.txt', 'w') as file:\n",
    "    for numbers in list_of_integer:\n",
    "        file.write(f\"{numbers}\\n\")\n",
    "\n",
    "#Printing the numbers using the cat command, cant use cat on windows, so have to use type\n",
    "print('The data_int.txt file:')\n",
    "!type data_int.txt\n",
    "\n",
    "#Creating the 5x5 matrix with random float numbers\n",
    "float_matrix = np.random.rand(5,5)\n",
    "np.savetxt('data_float.txt', float_matrix)\n",
    "print('The data_float.txt file:')\n",
    "!type data_float.txt\n",
    "\n",
    "# Load the txt file\n",
    "loaded_float_matrix = np.loadtxt('data_float.txt')\n",
    "\n",
    "# Save the matrix to a csv file\n",
    "csv_file_path = 'data_float.csv'\n",
    "\n",
    "with open(csv_file_path, 'w', newline='') as csv_file:\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    csv_writer.writerows(loaded_float_matrix)\n",
    "\n",
    "# Print the content of the csv file using the type command(windows)\n",
    "print('The data_float.csv printed: ')\n",
    "!type data_float.csv  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. **JSON files**\n",
    "\n",
    "Load the file `user_data.json`, which can be found at:\n",
    "\n",
    "- https://www.dropbox.com/s/sz5klcdpckc39hd/user_data.json\n",
    "\n",
    "and filter the data by the \"CreditCardType\" when it equals to \"American Express\". Than save the data to a new CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Data:\n",
      "      ID               JobTitle                       EmailAddress  \\\n",
      "1      2    Investment  Advisor       Clint_Thorpe5003@bulaffy.com   \n",
      "11    12         Retail Trainee   Phillip_Carpenter9505@famism.biz   \n",
      "27    28        Project Manager        Russel_Graves1378@extex.org   \n",
      "38    39            Stockbroker       Leanne_Newton1268@typill.biz   \n",
      "56    57         Budget Analyst          Tony_Giles1960@iatim.tech   \n",
      "61    62           CNC Operator        Owen_Allcott5125@bauros.biz   \n",
      "67    68        Project Manager           Liam_Lynn3280@kideod.biz   \n",
      "73    74                Dentist      Regina_Woodcock5820@yahoo.com   \n",
      "80    81          HR Specialist       Carter_Wallace9614@atink.com   \n",
      "91    92    Staffing Consultant           Maia_Stark2797@jiman.org   \n",
      "96    97            Stockbroker          Ciara_Lomax982@bauros.biz   \n",
      "115  116    Staffing Consultant      Isabel_Ellwood1475@fuliss.net   \n",
      "147  148           CNC Operator  Abdul_Townend2202@infotech44.tech   \n",
      "149  150             Fabricator        Caleb_Poulton1735@atink.com   \n",
      "150  151     Restaurant Manager         Ronald_Lewis6777@deavo.com   \n",
      "153  154                Bellman        Faith_Seymour3829@twace.org   \n",
      "168  169        Assistant Buyer      Anthony_Hancock9083@qater.org   \n",
      "175  176  Healthcare Specialist    Isabella_Willson5478@nanoff.biz   \n",
      "181  182             Pharmacist     Stephanie_Darcy3298@bauros.biz   \n",
      "198  199    Investment  Advisor         Ryan_Kennedy5565@corti.com   \n",
      "\n",
      "     FirstNameLastName           CreditCard    CreditCardType  \n",
      "1         Clint Thorpe  7083-8766-0251-2345  American Express  \n",
      "11   Phillip Carpenter  3657-0088-0820-5247  American Express  \n",
      "27       Russel Graves  6718-4818-8011-6024  American Express  \n",
      "38       Leanne Newton  5438-0816-4166-4847  American Express  \n",
      "56          Tony Giles  8130-3425-7573-7745  American Express  \n",
      "61        Owen Allcott  4156-0107-7210-2630  American Express  \n",
      "67           Liam Lynn  7152-3247-6053-2233  American Express  \n",
      "73     Regina Woodcock  0208-1753-3870-8002  American Express  \n",
      "80      Carter Wallace  4256-7201-6717-4322  American Express  \n",
      "91          Maia Stark  3851-1403-1734-6321  American Express  \n",
      "96         Ciara Lomax  3702-3440-2472-5424  American Express  \n",
      "115     Isabel Ellwood  3738-0882-0066-6683  American Express  \n",
      "147      Abdul Townend  4224-1226-3557-3448  American Express  \n",
      "149      Caleb Poulton  8203-6875-5225-0341  American Express  \n",
      "150       Ronald Lewis  7212-0155-5014-8471  American Express  \n",
      "153      Faith Seymour  4170-5186-6887-6558  American Express  \n",
      "168    Anthony Hancock  0832-3357-6010-6550  American Express  \n",
      "175   Isabella Willson  5177-4868-4623-0384  American Express  \n",
      "181    Stephanie Darcy  0264-4020-5106-5576  American Express  \n",
      "198       Ryan Kennedy  3166-6287-6242-7207  American Express  \n",
      "\n",
      "CSV File Saved at: data_float.csv\n"
     ]
    }
   ],
   "source": [
    "#JSON filepaht\n",
    "JSON_file = 'user_data.json'\n",
    "\n",
    "with open(JSON_file, 'r') as json_file:\n",
    "    jason_data = pd.read_json(json_file)\n",
    "\n",
    "#Converting jason_data to a DataFrame\n",
    "df = pd.DataFrame(jason_data)\n",
    "\n",
    "#Filtering the data, when CreditCardType equals American express\n",
    "filtered_data = df[df['CreditCardType'] == 'American Express'] #New dataframe only containing the data that meets the cond. \n",
    "\n",
    "#Saving to csv\n",
    "filtered_data.to_csv('user_data.csv', index = None)\n",
    "\n",
    "#Printing the filtered data\n",
    "print(\"Filtered Data:\")\n",
    "print(filtered_data)\n",
    "print(\"\\nCSV File Saved at:\", csv_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. **CSV files with Pandas**\n",
    "\n",
    "Load the file from this url:\n",
    "\n",
    "- https://www.dropbox.com/s/kgshemfgk22iy79/mushrooms_categorized.csv\n",
    "\n",
    "with Pandas. \n",
    "\n",
    "+ explore and print the DataFrame\n",
    "+ calculate, using `groupby()`, the average value of each feature, separately for each class\n",
    "+ save the file in a JSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DataFrame: \n",
      "      class  cap-shape  cap-surface  cap-color  bruises  odor  \\\n",
      "0         1          5            2          4        1     6   \n",
      "1         0          5            2          9        1     0   \n",
      "2         0          0            2          8        1     3   \n",
      "3         1          5            3          8        1     6   \n",
      "4         0          5            2          3        0     5   \n",
      "...     ...        ...          ...        ...      ...   ...   \n",
      "8119      0          3            2          4        0     5   \n",
      "8120      0          5            2          4        0     5   \n",
      "8121      0          2            2          4        0     5   \n",
      "8122      1          3            3          4        0     8   \n",
      "8123      0          5            2          4        0     5   \n",
      "\n",
      "      gill-attachment  gill-spacing  gill-size  gill-color  ...  \\\n",
      "0                   1             0          1           4  ...   \n",
      "1                   1             0          0           4  ...   \n",
      "2                   1             0          0           5  ...   \n",
      "3                   1             0          1           5  ...   \n",
      "4                   1             1          0           4  ...   \n",
      "...               ...           ...        ...         ...  ...   \n",
      "8119                0             0          0          11  ...   \n",
      "8120                0             0          0          11  ...   \n",
      "8121                0             0          0           5  ...   \n",
      "8122                1             0          1           0  ...   \n",
      "8123                0             0          0          11  ...   \n",
      "\n",
      "      stalk-surface-below-ring  stalk-color-above-ring  \\\n",
      "0                            2                       7   \n",
      "1                            2                       7   \n",
      "2                            2                       7   \n",
      "3                            2                       7   \n",
      "4                            2                       7   \n",
      "...                        ...                     ...   \n",
      "8119                         2                       5   \n",
      "8120                         2                       5   \n",
      "8121                         2                       5   \n",
      "8122                         1                       7   \n",
      "8123                         2                       5   \n",
      "\n",
      "      stalk-color-below-ring  veil-type  veil-color  ring-number  ring-type  \\\n",
      "0                          7          0           2            1          4   \n",
      "1                          7          0           2            1          4   \n",
      "2                          7          0           2            1          4   \n",
      "3                          7          0           2            1          4   \n",
      "4                          7          0           2            1          0   \n",
      "...                      ...        ...         ...          ...        ...   \n",
      "8119                       5          0           1            1          4   \n",
      "8120                       5          0           0            1          4   \n",
      "8121                       5          0           1            1          4   \n",
      "8122                       7          0           2            1          0   \n",
      "8123                       5          0           1            1          4   \n",
      "\n",
      "      spore-print-color  population  habitat  \n",
      "0                     2           3        5  \n",
      "1                     3           2        1  \n",
      "2                     3           2        3  \n",
      "3                     2           3        5  \n",
      "4                     3           0        1  \n",
      "...                 ...         ...      ...  \n",
      "8119                  0           1        2  \n",
      "8120                  0           4        2  \n",
      "8121                  0           1        2  \n",
      "8122                  7           4        2  \n",
      "8123                  4           1        2  \n",
      "\n",
      "[8124 rows x 23 columns]\n",
      "Printing info: \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8124 entries, 0 to 8123\n",
      "Data columns (total 23 columns):\n",
      " #   Column                    Non-Null Count  Dtype\n",
      "---  ------                    --------------  -----\n",
      " 0   class                     8124 non-null   int64\n",
      " 1   cap-shape                 8124 non-null   int64\n",
      " 2   cap-surface               8124 non-null   int64\n",
      " 3   cap-color                 8124 non-null   int64\n",
      " 4   bruises                   8124 non-null   int64\n",
      " 5   odor                      8124 non-null   int64\n",
      " 6   gill-attachment           8124 non-null   int64\n",
      " 7   gill-spacing              8124 non-null   int64\n",
      " 8   gill-size                 8124 non-null   int64\n",
      " 9   gill-color                8124 non-null   int64\n",
      " 10  stalk-shape               8124 non-null   int64\n",
      " 11  stalk-root                8124 non-null   int64\n",
      " 12  stalk-surface-above-ring  8124 non-null   int64\n",
      " 13  stalk-surface-below-ring  8124 non-null   int64\n",
      " 14  stalk-color-above-ring    8124 non-null   int64\n",
      " 15  stalk-color-below-ring    8124 non-null   int64\n",
      " 16  veil-type                 8124 non-null   int64\n",
      " 17  veil-color                8124 non-null   int64\n",
      " 18  ring-number               8124 non-null   int64\n",
      " 19  ring-type                 8124 non-null   int64\n",
      " 20  spore-print-color         8124 non-null   int64\n",
      " 21  population                8124 non-null   int64\n",
      " 22  habitat                   8124 non-null   int64\n",
      "dtypes: int64(23)\n",
      "memory usage: 1.4 MB\n",
      "None\n",
      "Average by class: \n",
      "       cap-shape  cap-surface  cap-color   bruises      odor  gill-attachment  \\\n",
      "class                                                                           \n",
      "0       3.266160     1.615970   4.581749  0.653992  4.334601         0.954373   \n",
      "1       3.436159     2.055158   4.421859  0.159346  3.940756         0.995403   \n",
      "\n",
      "       gill-spacing  gill-size  gill-color  stalk-shape  ...  \\\n",
      "class                                                    ...   \n",
      "0          0.285171   0.068441    6.622624     0.615970  ...   \n",
      "1          0.028601   0.567926    2.863636     0.514811  ...   \n",
      "\n",
      "       stalk-surface-below-ring  stalk-color-above-ring  \\\n",
      "class                                                     \n",
      "0                      1.798479                6.098859   \n",
      "1                      1.394280                5.512768   \n",
      "\n",
      "       stalk-color-below-ring  veil-type  veil-color  ring-number  ring-type  \\\n",
      "class                                                                          \n",
      "0                    6.064639        0.0    1.931559     1.125475   3.007605   \n",
      "1                    5.504597        0.0    2.002043     1.009193   1.522983   \n",
      "\n",
      "       spore-print-color  population   habitat  \n",
      "class                                           \n",
      "0               3.201521    3.283270  1.148289  \n",
      "1               4.021450    4.031665  1.895812  \n",
      "\n",
      "[2 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "#Saving filepath\n",
    "csv_file = 'mushrooms_categorized.csv'\n",
    "#Loading the dataframe\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "#Setting display options\n",
    "#pd.set_option('display.max_rows', None)\n",
    "#pd.set_option('display.max_columns', None)\n",
    "\n",
    "#Exploring and printing\n",
    "print('The DataFrame: ')\n",
    "print(df)\n",
    "\n",
    "print('Printing info: ')\n",
    "print(df.info())\n",
    "\n",
    "#Grouping \n",
    "average_by_class = df.groupby(['class']).mean()\n",
    "print('Average by class: ')\n",
    "print(average_by_class)\n",
    "\n",
    "#Resetting display options\n",
    "pd.reset_option('display.max_rows')\n",
    "pd.reset_option('display.max_columns')\n",
    "\n",
    "#saving the file in JSON format\n",
    "df.to_json('mushroom_cathergories.json', orient = 'index')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. **Reading a database**\n",
    "\n",
    "Get the database `sakila.db` from the lecture `06_dataio.ipynb`, and import the table `actors` as a Pandas dataframe. Using the dataframe, count how many actors have a first name that begins with `A`.\n",
    "\n",
    "*Hint:* use the Series `.str` method to apply the Python string methods to the elements of a Series, see [documentation](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of actors with a first name starting with 'A': 13\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "# Downloading the sakila.db file\n",
    "url = \"https://gist.github.com/Piyush3dB/726bf7012785d6e0fd691c3655c92654/raw/2c17ccb2eb33b3396bfa96284c53f0718a4ea62c/sakila.db\"\n",
    "file_name = \"./data/sakila.db\"\n",
    "urllib.request.urlretrieve(url, file_name)\n",
    "\n",
    "# Connecting to the database and import the actors table\n",
    "conn = sql.connect(file_name)\n",
    "query = \"SELECT * FROM actor\"\n",
    "df = pd.read_sql_query(query, conn)\n",
    "\n",
    "# Counting actors with a first name starting with 'A'\n",
    "count_a_actors = df[df[\"first_name\"].str.startswith('A', na=False)].shape[0]\n",
    "\n",
    "# Printing the result\n",
    "print(f\"Number of actors with a first name starting with 'A': {count_a_actors}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. **Reading the credit card numbers**\n",
    "\n",
    "Get the binary file named `credit_card.dat` from this address:\n",
    "\n",
    "- https://www.dropbox.com/s/8m0syw2tkul3dap/credit_card.dat\n",
    "\n",
    "and convert the data into the real credit card number, knowing that:\n",
    "- each line corresponds to a credit card number, which consists of 16 characters (which are numbers in the 0-9 range) divided in 4 blocks, with a whitespace between each block\n",
    "- each character is written using a 6 bit binary representation (including the whitespace)\n",
    "- the final 4 bits of each line are a padding used to determine the end of the line, and can be ignored\n",
    "\n",
    "*Hint*: convert the binary numbers to the decimal representation first, and then use the `chr()` function to convert the latter to a char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credit Card number 1: 7648 5673 3775 2271\n",
      "Credit Card number 2: 3257 8247 3354 2266\n",
      "Credit Card number 3: 2722 0001 4011 6652\n",
      "Credit Card number 4: 0661 3063 3742 3150\n",
      "Credit Card number 5: 0432 1608 1462 4742\n",
      "Credit Card number 6: 5827 2027 8785 7303\n",
      "Credit Card number 7: 5774 8528 2087 1117\n",
      "Credit Card number 8: 8140 1210 6352 2845\n",
      "Credit Card number 9: 5764 1133 7301 7100\n",
      "Credit Card number 10: 6456 1737 4126 6726\n",
      "Credit Card number 11: 1228 8631 7382 0000\n",
      "Credit Card number 12: 7051 0160 5374 3166\n",
      "Credit Card number 13: 0618 3587 1630 6376\n",
      "Credit Card number 14: 1545 5454 7444 5636\n",
      "Credit Card number 15: 6735 3116 3202 6834\n",
      "Credit Card number 16: 7287 5011 1547 8413\n",
      "Credit Card number 17: 7033 2607 3328 4200\n",
      "Credit Card number 18: 2568 5244 1874 5024\n",
      "Credit Card number 19: 1684 2253 7570 7118\n",
      "Credit Card number 20: 0672 2576 0575 6631\n",
      "Credit Card number 21: 6332 8353 8787 1340\n",
      "Credit Card number 22: 1813 3361 1175 4211\n",
      "Credit Card number 23: 2477 6450 8840 2368\n",
      "Credit Card number 24: 5512 3505 2563 1326\n",
      "Credit Card number 25: 3083 7882 0621 0025\n",
      "Credit Card number 26: 4521 5148 8045 0334\n",
      "Credit Card number 27: 7563 3654 8713 5787\n",
      "Credit Card number 28: 8324 2664 0476 5561\n",
      "Credit Card number 29: 0565 2504 7168 3510\n",
      "Credit Card number 30: 5107 5507 1767 0738\n",
      "Credit Card number 31: 2462 1821 2448 1443\n",
      "Credit Card number 32: 2788 0638 6861 6554\n",
      "Credit Card number 33: 5851 5873 5474 0547\n",
      "Credit Card number 34: 0670 1004 4013 2655\n",
      "Credit Card number 35: 5874 5506 3048 0806\n",
      "Credit Card number 36: 2805 5401 8462 1260\n",
      "Credit Card number 37: 5083 8406 6310 1862\n",
      "Credit Card number 38: 1076 1445 3013 2266\n",
      "Credit Card number 39: 8440 4804 4844 5277\n",
      "Credit Card number 40: 4758 6141 0686 1387\n",
      "Credit Card number 41: 7586 0675 0315 2568\n",
      "Credit Card number 42: 2544 1258 7432 5165\n",
      "Credit Card number 43: 3474 5023 4434 5626\n",
      "Credit Card number 44: 1410 0270 0434 5086\n",
      "Credit Card number 45: 7315 4446 1104 4215\n",
      "Credit Card number 46: 0224 7742 8300 0266\n",
      "Credit Card number 47: 0170 2700 3145 0640\n",
      "Credit Card number 48: 2006 2437 8054 1600\n",
      "Credit Card number 49: 8142 4055 1776 0026\n",
      "Credit Card number 50: 3026 7380 1241 1084\n",
      "Credit Card number 51: \n"
     ]
    }
   ],
   "source": [
    "file_name = \"credit_card.dat\"\n",
    "\n",
    "# Function for converting binary to decimal and then chr\n",
    "def binary_to_credit_card(bin_str):\n",
    "    # Convert each 6-bit to decimal \n",
    "    bit_group = [bin_str[i:i + 6] for i in range(0, len(bin_str) - 4, 6)]\n",
    "    return ''.join(chr(int(chunk, 2)) for chunk in bit_group)\n",
    "\n",
    "#Reading the binary data from the file\n",
    "with open(file_name, \"rb\") as file:\n",
    "    for line_number, line in enumerate(file, start=1):\n",
    "        bin_blocks = line[:-1].split()\n",
    "        card_number = ''.join(binary_to_credit_card(block) for block in bin_blocks)\n",
    "        print(f\"Credit Card number {line_number}: {card_number}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. **Write data to a binary file**\n",
    "\n",
    "a) Start from the `data/data_000637.txt` file that we have used during the previous lectures, and convert it to a binary file according to the format defined below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion completed. The binary file saved to: data_000637.dat\n",
      "Size of text file: 33179236 bytes\n",
      "Size of binary file: 480 bytes\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"images/data_format.png\")\n",
    "\n",
    "def conv_txt_to_binary(in_txt, out_dat):\n",
    "    #Reading the first ten lines of the file to df\n",
    "    df = pd.read_csv(in_txt, nrows=10)\n",
    "\n",
    "    #Opening the binary file in write\n",
    "    with open(out_dat, 'wb') as binary_file:\n",
    "        #Iterating over the rows\n",
    "        for _, row in df.iterrows():\n",
    "            #Packing the values into a single 64-bit integer word\n",
    "            word = struct.pack('<qqqqqq', *map(int, row))\n",
    "\n",
    "            #Writing the 64-bit word to the binary file\n",
    "            binary_file.write(word)\n",
    "\n",
    "    print(f\"Conversion completed. The binary file saved to: {out_dat}\")\n",
    "\n",
    "conv_txt_to_binary('data_000637.txt', 'data_000637.dat')\n",
    "\n",
    "#Task C, printing the size of the two files. The size of the text file is much bigger that the binary file as expected\n",
    "txt_size = os.path.getsize('data_000637.txt')\n",
    "dat_size = os.path.getsize('data_000637.dat')\n",
    "\n",
    "print(f\"Size of text file: {txt_size} bytes\")\n",
    "print(f\"Size of binary file: {dat_size} bytes\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hints*:\n",
    "- Read the first 10 lines using Pandas\n",
    "- Iterate over the DataFrame rows\n",
    "- For every row, \"pack\" the values (features) into a single 64-bit word, according to the format specified above. Use bit-wise shifts and operators to do so.\n",
    "- Write each 64-bit word to a binary file. You can use `struct` in this way:\n",
    "```\n",
    "binary_file.write( struct.pack('<q', word) )\n",
    "```\n",
    "where `word` is the 64-bit word.\n",
    "- Close the file after completing the loop.\n",
    "\n",
    "b) Check that the binary file is correctly written by reading it with the code used in the lecture `06_dataio.ipynb`, and verify that the content of the `txt` and binary files is consistent.\n",
    "\n",
    "c) What is the difference of the size on disk between equivalent `txt` and binary files?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HEAD</th>\n",
       "      <th>FPGA</th>\n",
       "      <th>CHANNEL</th>\n",
       "      <th>ORBIT_CNT</th>\n",
       "      <th>BX_CNT</th>\n",
       "      <th>TDC_MEAS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>424</td>\n",
       "      <td>588653088</td>\n",
       "      <td>2602</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>2946605610</td>\n",
       "      <td>354</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>295</td>\n",
       "      <td>2519081639</td>\n",
       "      <td>626</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>42</td>\n",
       "      <td>656519082</td>\n",
       "      <td>586</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>39</td>\n",
       "      <td>715628975</td>\n",
       "      <td>2754</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>175</td>\n",
       "      <td>2711759382</td>\n",
       "      <td>658</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>24</td>\n",
       "      <td>370705705</td>\n",
       "      <td>2570</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>155</td>\n",
       "      <td>471438873</td>\n",
       "      <td>2449</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>278</td>\n",
       "      <td>463149208</td>\n",
       "      <td>385</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>133</td>\n",
       "      <td>454628890</td>\n",
       "      <td>441</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    HEAD  FPGA  CHANNEL   ORBIT_CNT  BX_CNT  TDC_MEAS\n",
       "1      1     1      424   588653088    2602         8\n",
       "2      1     2       33  2946605610     354         1\n",
       "3      1     4      295  2519081639     626         1\n",
       "4      0    11       42   656519082     586         2\n",
       "5      1     5       39   715628975    2754         2\n",
       "6      1     3      175  2711759382     658         5\n",
       "7      0    11       24   370705705    2570         5\n",
       "8      0    14      155   471438873    2449        17\n",
       "9      0    12      278   463149208     385        18\n",
       "10     0    12      133   454628890     441        19"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import struct, time\n",
    "\n",
    "data = {}\n",
    "\n",
    "with open('data_000637.txt', 'rb') as file:\n",
    "    file_content = file.read()\n",
    "    word_counter = 0\n",
    "    word_size = 8 # size of the word in bytes\n",
    "    for i in range(0, len(file_content), word_size):\n",
    "        word_counter += 1\n",
    "        if word_counter > 10: break\n",
    "        word = struct.unpack('<q', file_content[i : i + word_size])[0] # get an 8-byte word\n",
    "        head     = (word >> 62) & 0x3\n",
    "        fpga     = (word >> 58) & 0xF\n",
    "        tdc_chan = (word >> 49) & 0x1FF\n",
    "        orb_cnt  = (word >> 17) & 0xFFFFFFFF\n",
    "        bx       = (word >> 5 ) & 0xFFF\n",
    "        tdc_meas = (word >> 0 ) & 0x1F\n",
    "        #if i == 0: print ('{0}\\t{1}\\t{2}\\t{3}\\t{4}\\t{5}'.format('HEAD', 'FPGA', 'CHANNEL', 'ORBIT_CNT', 'BX_CNT', 'TDC_MEAS'))\n",
    "        #print('{0}\\t{1}\\t{2}\\t{3}\\t{4}\\t{5}'.format(head, fpga, tdc_chan, orb_cnt, bx, tdc_meas))\n",
    "        entry = {'HEAD' : head, 'FPGA' : fpga, 'CHANNEL' : tdc_chan, 'ORBIT_CNT' : orb_cnt, 'BX_CNT' : bx, 'TDC_MEAS' : tdc_meas}\n",
    "        #df = df.append(entry, ignore_index=True)\n",
    "        data[word_counter] = entry\n",
    "        \n",
    "df = pd.DataFrame(data).T\n",
    "df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
